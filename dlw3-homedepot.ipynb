{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4853,"databundleVersionId":36114,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports & Setup","metadata":{}},{"cell_type":"code","source":"!pip -q install torchsummary\n!pip -q install transformers\n!pip -q install tokenizers","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:27:59.161602Z","iopub.execute_input":"2024-03-25T13:27:59.162388Z","iopub.status.idle":"2024-03-25T13:28:37.386910Z","shell.execute_reply.started":"2024-03-25T13:27:59.162336Z","shell.execute_reply":"2024-03-25T13:28:37.385683Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Standard library imports\nimport re\nfrom collections import Counter\nimport os\nfrom time import time\n\n# Third-party library imports for data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nfrom tokenizers import ByteLevelBPETokenizer\n\n# PyTorch and related library imports for deep learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset, Subset\n\nimport pytorch_lightning as pl\n\n# Transformers library imports for NLP\nfrom transformers import BertModel, BertTokenizer\n\n# Gensim library imports for word embeddings and nltk for text processing\nfrom gensim.models import Word2Vec\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# Matplotlib library imports for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Wandb library imports for experiment tracking\nimport wandb\n\n# Other utility and helper imports\nfrom torchsummary import summary\nfrom tqdm import tqdm\nfrom kaggle_secrets import UserSecretsClient","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:05.759954Z","iopub.execute_input":"2024-03-25T13:29:05.760324Z","iopub.status.idle":"2024-03-25T13:29:26.014273Z","shell.execute_reply.started":"2024-03-25T13:29:05.760297Z","shell.execute_reply":"2024-03-25T13:29:26.013308Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:26.015824Z","iopub.execute_input":"2024-03-25T13:29:26.016110Z","iopub.status.idle":"2024-03-25T13:29:28.739330Z","shell.execute_reply.started":"2024-03-25T13:29:26.016084Z","shell.execute_reply":"2024-03-25T13:29:28.738257Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"class Hyperparameters:\n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\nhp = Hyperparameters(\n    # setup\n    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    seed=2024,\n\n    # data\n    val_ratio=0.1,\n    batch_size=128,\n    max_len=512,\n    num_workers=0,\n    \n    # model\n    hidden_size=128,\n    \n    # training\n    learning_rate=1e-3,\n    max_lr=0.01,\n    num_epochs=30,\n    patience=3,\n    \n    criterion=nn.CrossEntropyLoss(),\n    optimizer=optim.AdamW,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:28.740447Z","iopub.execute_input":"2024-03-25T13:29:28.741009Z","iopub.status.idle":"2024-03-25T13:29:28.770325Z","shell.execute_reply.started":"2024-03-25T13:29:28.740981Z","shell.execute_reply":"2024-03-25T13:29:28.769324Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"torch.multiprocessing.set_start_method('spawn')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:28.772867Z","iopub.execute_input":"2024-03-25T13:29:28.773242Z","iopub.status.idle":"2024-03-25T13:29:28.788796Z","shell.execute_reply.started":"2024-03-25T13:29:28.773206Z","shell.execute_reply":"2024-03-25T13:29:28.787876Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"root = '/kaggle/input/home-depot-product-search-relevance'\n\ntrain_path = f'{root}/train.csv.zip'\ntest_path = f'{root}/test.csv.zip'\ntest_labels_path = f'{root}/sample_submission.csv.zip'\nproduct_path = f'{root}/product_descriptions.csv.zip'\nattributes_path = f'{root}/attributes.csv.zip'","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:28.789841Z","iopub.execute_input":"2024-03-25T13:29:28.790095Z","iopub.status.idle":"2024-03-25T13:29:28.800146Z","shell.execute_reply.started":"2024-03-25T13:29:28.790073Z","shell.execute_reply":"2024-03-25T13:29:28.799317Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_set = pd.read_csv(train_path, encoding='ISO-8859-1')\ntest_set = pd.read_csv(test_path, encoding='ISO-8859-1')\ntest_labels =  pd.read_csv(test_labels_path)\nproduct_df = pd.read_csv(product_path)\nattributes_df = pd.read_csv(attributes_path)\n\ntest_set = pd.merge(test_set, test_labels, on='id')\ntest_set = test_set[test_set['relevance'] != -1]","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:28.801212Z","iopub.execute_input":"2024-03-25T13:29:28.801461Z","iopub.status.idle":"2024-03-25T13:29:33.915731Z","shell.execute_reply.started":"2024-03-25T13:29:28.801441Z","shell.execute_reply":"2024-03-25T13:29:33.914885Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Display a few rows of the loaded data\nprint(\"Training Data:\")\nprint(train_set.head())\n\nprint(\"\\nTesting Data:\")\nprint(test_set.head())\n\nprint(\"\\nAttributes Data:\")\nprint(attributes_df.head())\n\nprint(\"\\nDescriptions Data:\")\nprint(product_df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_set.info())\nprint()\nprint(train_set.isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"training data shape is:\", train_set.shape)\nprint(\"testing data shape is:\", test_set.shape)\nprint(\"attribute data shape is:\", attributes_df.shape)\nprint(\"description data shape is:\", product_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of unique product\nlen(train_set['product_uid'].unique()) # 54667 rather than 74067","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set['search_len'] = train_set['search_term'].apply(len)  # length of search term\ntrain_set['product_len'] = train_set['product_title'].apply(len)  # length of pro","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\n\n# tokenize the words in the 'search_term' column\nsearch_term_words = train_set['search_term'].apply(word_tokenize).tolist()\nsearch_term_words = [word for sublist in search_term_words for word in sublist]\n\n# calculate the frequency of each word\nsearch_term_freq = Counter(search_term_words)\n\n# print the most common words\nsearch_term_freq.most_common(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set[['search_len', 'product_len', 'relevance']].corr()  # correlation between length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some statistic about relevance score\nprint(train_set['relevance'].value_counts())\ntrain_set['relevance'].hist(bins=13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore distribution of relevance scores\nplt.figure(figsize=(10, 6))\nsns.histplot(train_set['relevance'], bins=30, kde=True)\nplt.title('Distribution of Relevance Scores on Training Data')\nplt.xlabel('Relevance Score')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Histogram for 'search_len'\nplt.hist(train_set['search_len'], bins=20, color='skyblue', edgecolor='black')\nplt.xlabel('Search Length')\nplt.ylabel('Frequency')\nplt.title('Histogram of Search Length')\nplt.show()\n\n# Histogram for 'product_len'\nplt.hist(train_set['product_len'], bins=20, color='salmon', edgecolor='black')\nplt.xlabel('Product Title Length')\nplt.ylabel('Frequency')\nplt.title('Histogram of Product Length')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore the relationship between relevance and the length of the search term\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='search_len', y='relevance', data=train_set)\nplt.title('Relevance vs. Search Term Length')\nplt.xlabel('Search Term Length')\nplt.ylabel('Relevance Score')\nplt.show()\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='product_len', y='relevance', data=train_set)\nplt.title('Relevance vs. Search Term Length')\nplt.xlabel('Product Title Length')\nplt.ylabel('Relevance Score')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate token lengths for each description\npd_token_len = pd.Series(map(lambda x: len(x.split()), product_df['product_description'].tolist()))\n\n# Print value counts\nprint(pd_token_len.value_counts())\n\n# Create histogram\npd_token_len.hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 155 entries have no data\nattributes_df[attributes_df['product_uid'].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Naive model","metadata":{}},{"cell_type":"code","source":"# Create features using CountVectorizer\nvectorizer = CountVectorizer(analyzer='char')\nX_product = vectorizer.fit_transform(train_set['product_title'])\nX_search = vectorizer.transform(train_set['search_term'])\n\n# Combine the features\nX = X_product + X_search\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, train_set['relevance'], test_size=0.2, random_state=42)\n\n# test set\nX_test_product = vectorizer.transform(test_set['product_title'])\nX_test_search = vectorizer.transform(test_set['search_term'])\nX_test = X_test_product + X_test_search\ny_test = test_set['relevance']\n\n# # Train a Random Forest model\n# t = time()\n\n# regressor_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n# regressor_rf.fit(X_train, y_train)\n\n# print(f\"RF training time: {time() - t:.2f}s\")\n\n# Train an XGBoost model\nt = time()\n\nregressor_xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\nregressor_xgb.fit(X_train, y_train)\n\nprint(f\"XGB training time: {time() - t:.2f}s\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions\n# y_train_pred_rf = regressor_rf.predict(X_train)\n# y_val_pred_rf = regressor_rf.predict(X_val)\n# y_test_pred_rf = regressor_rf.predict(X_test)\n\ny_train_pred_xgb = regressor_xgb.predict(X_train)\ny_val_pred_xgb = regressor_xgb.predict(X_val)\ny_test_pred_xgb = regressor_xgb.predict(X_test)\n\n# Evaluate the models\n# train_rmse_rf = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))\n# val_rmse_rf = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n# test_rmse_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n\n# train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n# val_mae_rf = mean_absolute_error(y_val, y_val_pred_rf)\n# test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n\ntrain_rmse_xgb = np.sqrt(mean_squared_error(y_train, y_train_pred_xgb))\nval_rmse_xgb = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\ntest_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n\ntrain_mae_xgb = mean_absolute_error(y_train, y_train_pred_xgb)\nval_mae_xgb = mean_absolute_error(y_val, y_val_pred_xgb)\ntest_mae_xgb = mean_absolute_error(y_test, y_test_pred_xgb)\n\n# print('\\nRandom Forest:')\n# print(f'Training RMSE: {train_rmse_rf:.4f}')\n# print(f'Validation RMSE: {val_rmse_rf:.4f}')\n# print(f'Test RMSE: {test_rmse_rf:.4f}')\n# print(f'Training MAE: {train_mae_rf:.4f}')\n# print(f'Validation MAE: {val_mae_rf:.4f}')\n# print(f'Test MAE: {test_mae_rf:.4f}')\n\nprint('\\nXGBoost:')\nprint(f'Training RMSE: {train_rmse_xgb:.4f}')\nprint(f'Validation RMSE: {val_rmse_xgb:.4f}')\nprint(f'Test RMSE: {test_rmse_xgb:.4f}')\nprint(f'Training MAE: {train_mae_xgb:.4f}')\nprint(f'Validation MAE: {val_mae_xgb:.4f}')\nprint(f'Test MAE: {test_mae_xgb:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Character Level Model","metadata":{}},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Remove 155 null entries in attribute table\nattributes_df = attributes_df.drop(attributes_df[attributes_df['product_uid'].isnull()].index, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:28:47.191999Z","iopub.status.idle":"2024-03-25T13:28:47.192315Z","shell.execute_reply.started":"2024-03-25T13:28:47.192159Z","shell.execute_reply":"2024-03-25T13:28:47.192172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge dataframes\ntrain_data = pd.merge(train_set, product_df, how='left', on='product_uid')\ntest_data = pd.merge(test_set, product_df, how='left', on='product_uid')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:28:47.193454Z","iopub.status.idle":"2024-03-25T13:28:47.193788Z","shell.execute_reply.started":"2024-03-25T13:28:47.193602Z","shell.execute_reply":"2024-03-25T13:28:47.193615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['search_term'] = train_data['search_term'].apply(list)\ntrain_data['product_title'] = train_data['product_title'].apply(list)\ntrain_data['product_description'] = train_data['product_description'].apply(list)\ntrain_data.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:28:47.195435Z","iopub.status.idle":"2024-03-25T13:28:47.195820Z","shell.execute_reply.started":"2024-03-25T13:28:47.195611Z","shell.execute_reply":"2024-03-25T13:28:47.195626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# same for test data\ntest_data['search_term'] = test_data['search_term'].apply(list)\ntest_data['product_title'] = test_data['product_title'].apply(list)\ntest_data['product_description'] = test_data['product_description'].apply(list)\ntest_data.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:28:47.196618Z","iopub.status.idle":"2024-03-25T13:28:47.196955Z","shell.execute_reply.started":"2024-03-25T13:28:47.196793Z","shell.execute_reply":"2024-03-25T13:28:47.196807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unique characters in the data\nunique_chars = set()\nfor s in train_data['search_term']:\n    unique_chars.update(s)\nfor s in train_data['product_title']:\n    unique_chars.update(s)\nfor s in train_data['product_description']:\n    unique_chars.update(s)\n\nfor s in test_data['search_term']:\n    unique_chars.update(s)\nfor s in test_data['product_title']:\n    unique_chars.update(s)\nfor s in test_data['product_description']:\n    unique_chars.update(s)\n\nlen(unique_chars)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:28:47.198073Z","iopub.status.idle":"2024-03-25T13:28:47.198394Z","shell.execute_reply.started":"2024-03-25T13:28:47.198234Z","shell.execute_reply":"2024-03-25T13:28:47.198248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class SearchRelevanceDataset(Dataset):\n    def __init__(self, df, unique_chars, max_len=512):\n        self.df = df\n        self.unique_chars = unique_chars\n        self.max_len = max_len\n\n        self.char2idx = {char: idx for idx, char in enumerate(self.unique_chars)}\n        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        product = self.df.iloc[idx]['product_title']\n        search = self.df.iloc[idx]['search_term']\n\n        # ids\n        product = [self.char2idx[char] for char in product]\n        search = [self.char2idx[char] for char in search]\n\n        # tensorize\n        product = torch.tensor(product).float()\n        search = torch.tensor(search).float()\n\n        # pad to max_len or truncate\n        if len(product) < self.max_len:\n            product = F.pad(product, (0, self.max_len - len(product)))\n        else:\n            product = product[:self.max_len]\n\n        if len(search) < self.max_len:\n            search = F.pad(search, (0, self.max_len - len(search)))\n        else:\n            search = search[:self.max_len]\n\n        relevance = torch.tensor(self.df.iloc[idx]['relevance']).float()\n        \n        return product.unsqueeze(-1), search.unsqueeze(-1), relevance","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:33.917475Z","iopub.execute_input":"2024-03-25T13:29:33.917789Z","iopub.status.idle":"2024-03-25T13:29:33.929091Z","shell.execute_reply.started":"2024-03-25T13:29:33.917763Z","shell.execute_reply":"2024-03-25T13:29:33.927950Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = SearchRelevanceDataset(train_data, unique_chars)\n\n# Split the dataset into training and validation sets\nval_size = int(hp.val_ratio * len(dataset))\ntrain_size = len(dataset) - val_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=hp.batch_size,\n                          num_workers=hp.num_workers,\n                          shuffle=True)\nval_loader = DataLoader(val_dataset,\n                        batch_size=hp.batch_size,\n                        num_workers=hp.num_workers,\n                        shuffle=False)\n\ntest_dataset = SearchRelevanceDataset(test_data, unique_chars)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=hp.batch_size,\n                         num_workers=hp.num_workers,\n                         shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:02:16.539964Z","iopub.execute_input":"2024-03-25T12:02:16.540243Z","iopub.status.idle":"2024-03-25T12:02:17.044438Z","shell.execute_reply.started":"2024-03-25T12:02:16.540220Z","shell.execute_reply":"2024-03-25T12:02:17.041694Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SearchRelevanceDataset(\u001b[43mtrain_data\u001b[49m, unique_chars)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and validation sets\u001b[39;00m\n\u001b[1;32m      4\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(hp\u001b[38;5;241m.\u001b[39mval_ratio \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"],"ename":"NameError","evalue":"name 'train_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"train_dataset[0][0].shape, train_dataset[1][0].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:02:17.045393Z","iopub.status.idle":"2024-03-25T12:02:17.045863Z","shell.execute_reply.started":"2024-03-25T12:02:17.045630Z","shell.execute_reply":"2024-03-25T12:02:17.045653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(train_loader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:02:17.047307Z","iopub.status.idle":"2024-03-25T12:02:17.047765Z","shell.execute_reply.started":"2024-03-25T12:02:17.047533Z","shell.execute_reply":"2024-03-25T12:02:17.047552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class SiameseLSTM(pl.LightningModule):\n    def __init__(self, input_dim, hidden_dim):\n        super(SiameseLSTM, self).__init__()\n\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True,dropout=0.4)\n        self.fc_out = nn.Linear(hidden_dim, 1)\n        self.sigmoid = nn.Sigmoid()\n\n        self.loss_fn = nn.MSELoss()\n        self.mae = nn.L1Loss()\n        self.bn = nn.BatchNorm1d(hidden_dim)  # Batch normalization layer\n\n    def forward_net(self, x):\n        _, (h, _) = self.lstm(x)  # h: (1, batch_size, hidden_dim)\n        \n        return h.squeeze(0)  # (batch_size, hidden_dim)\n\n    def forward(self, input1, input2):\n        output1 = self.forward_net(input1)\n        output2 = self.forward_net(input2)\n\n        diff = torch.abs(output1 - output2)\n        output = self.fc_out(diff)\n\n        output = self.sigmoid(output)\n\n        return output  # (batch_size, 1)\n\n    def training_step(self, batch, batch_idx):\n        product, search, relevance = batch\n        output = self(product, search)  # (batch_size, 1)\n\n        # normalize relevance - min is 1, max is 3\n        relevance = (relevance - 1) / 2  # (batch_size)\n\n        loss = self.loss_fn(output, relevance.unsqueeze(-1))\n        mae = self.mae(output, relevance.unsqueeze(-1))\n        \n        self.log('train_loss', loss)\n        self.log('train_mae', mae)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        product, search, relevance = batch\n        output = self(product, search)\n\n        # normalize relevance - min is 1, max is 3\n        relevance = (relevance - 1) / 2\n\n        loss = self.loss_fn(output, relevance.unsqueeze(-1))\n        mae = self.mae(output, relevance.unsqueeze(-1))\n\n        self.log('val_loss', loss)\n        self.log('val_mae', mae)\n\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        product, search, relevance = batch\n        output = self(product, search)\n\n        # normalize relevance - min is 1, max is 3\n        relevance = (relevance - 1) / 2\n\n        loss = self.loss_fn(output, relevance.unsqueeze(-1))\n        mae = self.mae(output, relevance.unsqueeze(-1))\n  \n        self.log('test_loss', loss)\n        self.log('test_mae', mae)\n\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:35.843161Z","iopub.execute_input":"2024-03-25T13:29:35.843543Z","iopub.status.idle":"2024-03-25T13:29:35.859014Z","shell.execute_reply.started":"2024-03-25T13:29:35.843506Z","shell.execute_reply":"2024-03-25T13:29:35.858073Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"input_dim = 1  # one character (input_id) at a time\nhidden_dim = hp.hidden_size\nmodel_char = SiameseLSTM(input_dim, hidden_dim)\n\nmodel_char.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:02:17.050600Z","iopub.status.idle":"2024-03-25T12:02:17.050895Z","shell.execute_reply.started":"2024-03-25T12:02:17.050745Z","shell.execute_reply":"2024-03-25T12:02:17.050757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check feedforward\nwith torch.no_grad():\n    product, search, relevance = train_dataset[0]\n\n    print(product.shape, search.shape)\n    \n    output = model_char(product.unsqueeze(0), search.unsqueeze(0))\n\n    print(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:02:17.052236Z","iopub.status.idle":"2024-03-25T12:02:17.052555Z","shell.execute_reply.started":"2024-03-25T12:02:17.052398Z","shell.execute_reply":"2024-03-25T12:02:17.052412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"logger = pl.loggers.WandbLogger(entity='questgen', project='dlw-ass3', log_model=True)\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min')\nearly_stopping = pl.callbacks.EarlyStopping(monitor='val_loss', patience=hp.patience, mode='min')\n\ntrainer = pl.Trainer(\n    accelerator='auto',\n    max_epochs=hp.num_epochs,\n    logger=logger,\n    callbacks=[checkpoint_callback, early_stopping],\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:13:21.612917Z","iopub.execute_input":"2024-03-24T19:13:21.613296Z","iopub.status.idle":"2024-03-24T19:13:23.715910Z","shell.execute_reply.started":"2024-03-24T19:13:21.613261Z","shell.execute_reply":"2024-03-24T19:13:23.714857Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model_char, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:13:23.717539Z","iopub.execute_input":"2024-03-24T19:13:23.717915Z","iopub.status.idle":"2024-03-24T19:28:54.450826Z","shell.execute_reply.started":"2024-03-24T19:13:23.717883Z","shell.execute_reply":"2024-03-24T19:28:54.449525Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatzmax\u001b[0m (\u001b[33mquestgen\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20240324_191323-6228d57d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/questgen/dlw-ass3/runs/6228d57d' target=\"_blank\">feasible-butterfly-36</a></strong> to <a href='https://wandb.ai/questgen/dlw-ass3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/questgen/dlw-ass3' target=\"_blank\">https://wandb.ai/questgen/dlw-ass3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/questgen/dlw-ass3/runs/6228d57d' target=\"_blank\">https://wandb.ai/questgen/dlw-ass3/runs/6228d57d</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ed4ad432e594fbbab923b07476ee50d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# load the best model\nmodel_char = SiameseLSTM.load_from_checkpoint(checkpoint_callback.best_model_path, hidden_dim=hp.hidden_size, input_dim=1)\n\ntrainer.test(model_char, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:28:54.452333Z","iopub.execute_input":"2024-03-24T19:28:54.452744Z","iopub.status.idle":"2024-03-24T19:29:54.014443Z","shell.execute_reply.started":"2024-03-24T19:28:54.452705Z","shell.execute_reply":"2024-03-24T19:29:54.012368Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a56ae14ad740c39661cf315e162b9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27223077416419983   \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5217583179473877    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27223077416419983    </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5217583179473877     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[{'test_loss': 0.27223077416419983, 'test_mae': 0.5217583179473877}]"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:29:54.015868Z","iopub.execute_input":"2024-03-24T19:29:54.016232Z","iopub.status.idle":"2024-03-24T19:29:57.686393Z","shell.execute_reply.started":"2024-03-24T19:29:54.016196Z","shell.execute_reply":"2024-03-24T19:29:57.685665Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.786 MB of 0.833 MB uploaded\\r'), FloatProgress(value=0.9438638112336497, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>train_loss</td><td>▆▄▃▃▄█▃▃▁▇▂▄▃▃▇▅▄▅▅▃▅▆▄▄▃▁▄▆▆▂▃▇▂▃▅▃▅▄▄▂</td></tr><tr><td>train_mae</td><td>▅▄▃▃▅█▃▃▁█▃▃▄▃▆▄▄▆▄▂▄▅▅▃▂▁▄▅▆▂▃▆▁▃▅▃▅▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>███▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>val_mae</td><td>████▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_loss</td><td>0.27223</td></tr><tr><td>test_mae</td><td>0.52176</td></tr><tr><td>train_loss</td><td>0.06254</td></tr><tr><td>train_mae</td><td>0.20514</td></tr><tr><td>trainer/global_step</td><td>7830</td></tr><tr><td>val_loss</td><td>0.09912</td></tr><tr><td>val_mae</td><td>0.26765</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">feasible-butterfly-36</strong> at: <a href='https://wandb.ai/questgen/dlw-ass3/runs/6228d57d' target=\"_blank\">https://wandb.ai/questgen/dlw-ass3/runs/6228d57d</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240324_191323-6228d57d/logs</code>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Word Level Model","metadata":{}},{"cell_type":"markdown","source":"## Word Preproccesing","metadata":{}},{"cell_type":"code","source":"# read the data again\ntrain_set = pd.read_csv(train_path, encoding='ISO-8859-1')\ntest_set = pd.read_csv(test_path, encoding='ISO-8859-1')\ntest_labels = pd.read_csv(test_labels_path)\nproduct_df = pd.read_csv(product_path)\nattributes_df = pd.read_csv(attributes_path)\n\ntest_set = pd.merge(test_set, test_labels, on='id')\ntest_set = test_set[test_set['relevance'] != -1]\n\n# merge the dataframes\ntrain_set = pd.merge(train_set, product_df, how='left', on='product_uid')\ntest_set = pd.merge(test_set, product_df, how='left', on='product_uid')\n\n# remove the 155 null entries in the attribute table\nattributes_df = attributes_df.drop(attributes_df[attributes_df['product_uid'].isnull()].index, axis=0)\n\n# merge the dataframes\ntrain_set = pd.merge(train_set, attributes_df, how='left', on='product_uid')\ntest_set = pd.merge(test_set, attributes_df, how='left', on='product_uid')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:40.634962Z","iopub.execute_input":"2024-03-25T13:29:40.635322Z","iopub.status.idle":"2024-03-25T13:29:46.650357Z","shell.execute_reply.started":"2024-03-25T13:29:40.635294Z","shell.execute_reply":"2024-03-25T13:29:46.649331Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_text = train_set['product_title'] + ' ' + train_set['product_description'] + ' ' + train_set['search_term']\ntrain_text = train_text.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:46.652079Z","iopub.execute_input":"2024-03-25T13:29:46.652376Z","iopub.status.idle":"2024-03-25T13:29:50.155917Z","shell.execute_reply.started":"2024-03-25T13:29:46.652351Z","shell.execute_reply":"2024-03-25T13:29:50.155098Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# create a tokenizer\nbpe_tokenizer = ByteLevelBPETokenizer()\n\n# train the tokenizer without using parallel processing\n# os.environ['TOKENIZERS_PARALLELISM'] = 'false'\nbpe_tokenizer.train_from_iterator(train_text, min_frequency=2)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:29:50.156959Z","iopub.execute_input":"2024-03-25T13:29:50.157222Z","iopub.status.idle":"2024-03-25T13:33:31.573147Z","shell.execute_reply.started":"2024-03-25T13:29:50.157201Z","shell.execute_reply":"2024-03-25T13:33:31.572147Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"bpe_tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:33:31.576737Z","iopub.execute_input":"2024-03-25T13:33:31.577053Z","iopub.status.idle":"2024-03-25T13:33:31.589802Z","shell.execute_reply.started":"2024-03-25T13:33:31.577027Z","shell.execute_reply":"2024-03-25T13:33:31.588777Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Tokenizer(vocabulary_size=30000, model=ByteLevelBPE, add_prefix_space=False, lowercase=False, dropout=None, unicode_normalizer=None, continuing_subword_prefix=None, end_of_word_suffix=None, trim_offsets=False)"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_train = bpe_tokenizer.encode_batch(train_text[:150_000])\ntokenized_train = [t.tokens for t in tokenized_train]","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:33:31.591804Z","iopub.execute_input":"2024-03-25T13:33:31.592419Z","iopub.status.idle":"2024-03-25T13:34:21.393319Z","shell.execute_reply.started":"2024-03-25T13:33:31.592385Z","shell.execute_reply":"2024-03-25T13:34:21.392282Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# train the word2vec model on the tokenized text\nword2vec_model = Word2Vec(tokenized_train, vector_size=100, window=5, min_count=1, workers=0)  # workers=0 for single core","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:21.394674Z","iopub.execute_input":"2024-03-25T13:34:21.395350Z","iopub.status.idle":"2024-03-25T13:34:30.778883Z","shell.execute_reply.started":"2024-03-25T13:34:21.395313Z","shell.execute_reply":"2024-03-25T13:34:29.498971Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class WordSearchRelevanceDataset(Dataset):\n    def __init__(self, df, tokenizer, word_embeddings, max_len=512):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.word_embeddings = word_embeddings\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        product = self.df.iloc[idx]['product_title']\n        search = self.df.iloc[idx]['search_term']\n\n        # convert to word embeddings\n        product = self.embed(product)  # shape: (seq_len, embedding_dim)\n        search = self.embed(search)  # shape: (seq_len, embedding_dim)\n\n        # pad to max_len or truncate\n        if product.shape[0] < self.max_len:\n            product = F.pad(product, (0, 0, 0, self.max_len - product.shape[0]))\n        else:\n            product = product[:self.max_len]\n\n        if search.shape[0] < self.max_len:\n            search = F.pad(search, (0, 0, 0, self.max_len - search.shape[0]))\n        else:\n            search = search[:self.max_len]\n\n        relevance = torch.tensor(self.df.iloc[idx]['relevance']).float()\n\n        return product, search, relevance\n    \n    def embed(self, text):\n        tokens = self.tokenizer.encode(text).tokens\n        embed = torch.tensor([self.word_embeddings[word] for word in tokens if word in self.word_embeddings])\n\n        if not embed.shape[0]:\n            embed = torch.zeros(self.word_embeddings.vector_size).unsqueeze(0)\n\n        return embed  # shape: (seq_len, embedding_dim)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:30.825508Z","iopub.execute_input":"2024-03-25T13:34:30.825859Z","iopub.status.idle":"2024-03-25T13:34:30.925091Z","shell.execute_reply.started":"2024-03-25T13:34:30.825828Z","shell.execute_reply":"2024-03-25T13:34:30.899189Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"dataset = WordSearchRelevanceDataset(train_set, bpe_tokenizer, word2vec_model.wv)\n\n# Split the dataset into training and validation sets\nval_size = int(hp.val_ratio * len(dataset))\ntrain_size = len(dataset) - val_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=hp.batch_size,\n                          num_workers=hp.num_workers,\n                          shuffle=True)\nval_loader = DataLoader(val_dataset,\n                        batch_size=hp.batch_size,\n                        num_workers=hp.num_workers,\n                        shuffle=False)\n\ntest_dataset = WordSearchRelevanceDataset(test_set, bpe_tokenizer, word2vec_model.wv)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=hp.batch_size,\n                         num_workers=hp.num_workers,\n                         shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:30.926319Z","iopub.execute_input":"2024-03-25T13:34:30.926626Z","iopub.status.idle":"2024-03-25T13:34:31.071707Z","shell.execute_reply.started":"2024-03-25T13:34:30.926599Z","shell.execute_reply":"2024-03-25T13:34:31.070931Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_dataset[0][0].shape, train_dataset[1][0].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:31.072742Z","iopub.execute_input":"2024-03-25T13:34:31.073029Z","iopub.status.idle":"2024-03-25T13:34:31.107160Z","shell.execute_reply.started":"2024-03-25T13:34:31.073005Z","shell.execute_reply":"2024-03-25T13:34:31.106114Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4149840782.py:36: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:261.)\n  embed = torch.tensor([self.word_embeddings[word] for word in tokens if word in self.word_embeddings])\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(torch.Size([512, 100]), torch.Size([512, 100]))"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(train_loader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:31.110159Z","iopub.execute_input":"2024-03-25T13:34:31.110462Z","iopub.status.idle":"2024-03-25T13:34:31.460308Z","shell.execute_reply.started":"2024-03-25T13:34:31.110436Z","shell.execute_reply":"2024-03-25T13:34:31.459359Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 512, 100])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training Word Model","metadata":{}},{"cell_type":"code","source":"model_word = SiameseLSTM(word2vec_model.vector_size,\n                         hp.hidden_size)\nmodel_word.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:31.461475Z","iopub.execute_input":"2024-03-25T13:34:31.461801Z","iopub.status.idle":"2024-03-25T13:34:31.481308Z","shell.execute_reply.started":"2024-03-25T13:34:31.461768Z","shell.execute_reply":"2024-03-25T13:34:31.480413Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"SiameseLSTM(\n  (lstm): LSTM(100, 128, batch_first=True, dropout=0.4)\n  (fc_out): Linear(in_features=128, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n  (loss_fn): MSELoss()\n  (mae): L1Loss()\n  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"logger = pl.loggers.WandbLogger(entity='questgen', project='dlw-ass3', log_model=True)\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min')\nearly_stopping = pl.callbacks.EarlyStopping(monitor='val_loss', patience=hp.patience, mode='min')\n\ntrainer = pl.Trainer(\n    accelerator='auto',\n    max_epochs=hp.num_epochs,\n    logger=logger,\n    callbacks=[checkpoint_callback, early_stopping],\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:31.482736Z","iopub.execute_input":"2024-03-25T13:34:31.483137Z","iopub.status.idle":"2024-03-25T13:34:32.215034Z","shell.execute_reply.started":"2024-03-25T13:34:31.483103Z","shell.execute_reply":"2024-03-25T13:34:32.214235Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model_word, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T13:34:32.216220Z","iopub.execute_input":"2024-03-25T13:34:32.216513Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkatzmax\u001b[0m (\u001b[33mquestgen\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20240325_133432-6xjyilib</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/questgen/dlw-ass3/runs/6xjyilib' target=\"_blank\">classic-thunder-44</a></strong> to <a href='https://wandb.ai/questgen/dlw-ass3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/questgen/dlw-ass3' target=\"_blank\">https://wandb.ai/questgen/dlw-ass3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/questgen/dlw-ass3/runs/6xjyilib' target=\"_blank\">https://wandb.ai/questgen/dlw-ass3/runs/6xjyilib</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1acdfcdc878b4b7886a459c6dcb33066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# load the best model\nmodel_word = SiameseLSTM.load_from_checkpoint(checkpoint_callback.best_model_path, hidden_dim=hp.hidden_size, input_dim=word2vec_model.vector_size)\n\ntrainer.test(model_word, test_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pretrained Bert Model","metadata":{}},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class BertSearchRelevanceDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        self.model = BertModel.from_pretrained('bert-base-uncased').to(hp.device)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        product = self.df.iloc[idx]['product_title']\n        search = self.df.iloc[idx]['search_term']\n\n        product = self.embed(product)\n        search = self.embed(search)\n\n        relevance = torch.tensor(self.df.iloc[idx]['relevance']).float()\n\n        return product, search, relevance\n    \n    def embed(self, text):\n        tokens = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(hp.device)\n        with torch.no_grad():\n            output = self.model(**tokens)\n        embed = output.last_hidden_state.mean(dim=1).squeeze()\n\n        return embed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = BertSearchRelevanceDataset(train_set)\n\n# Split the dataset into training and validation sets\nval_size = int(hp.val_ratio * len(dataset))\ntrain_size = len(dataset) - val_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=hp.batch_size,\n                          num_workers=hp.num_workers,\n                          shuffle=True)\nval_loader = DataLoader(val_dataset,\n                        batch_size=hp.batch_size,\n                        num_workers=hp.num_workers,\n                        shuffle=False)\n\ntest_dataset = BertSearchRelevanceDataset(test_set)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=hp.batch_size,\n                         num_workers=hp.num_workers,\n                         shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0][0].shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class SiameseLinear(pl.LightningModule):\n    def __init__(self, input_dim, hidden_dim):\n        super(SiameseLinear, self).__init__()\n\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, 128)\n        self.fc_out = nn.Linear(128, 1)\n        self.sigmoid = nn.Sigmoid()\n\n        self.loss_fn = nn.MSELoss()\n        self.mae = nn.L1Loss()\n\n    def forward_net(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n\n        return x\n    \n    def forward(self, input1, input2):\n        output1 = self.forward_net(input1)\n        output2 = self.forward_net(input2)\n\n        diff = torch.abs(output1 - output2)\n        output = self.fc_out(diff)\n\n        output = self.sigmoid(output)\n\n        return output\n\n    def training_step(self, batch, batch_idx):\n        product, search, relevance = batch\n        output = self(product, search)\n\n        # normalize relevance - min is 1, max is 3\n        relevance = (relevance - 1) / 2\n\n        loss = self.loss_fn(output, relevance.unsqueeze(1))\n        mae = self.mae(output, relevance.unsqueeze(1))\n        \n        self.log('train_loss', loss)\n        self.log('train_mae', mae)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        product, search, relevance = batch\n        output = self(product, search)\n\n        # normalize relevance - min is 1, max is 3\n        relevance = (relevance - 1) / 2\n\n        loss = self.loss_fn(output, relevance.unsqueeze(1))\n        mae = self.mae(output, relevance.unsqueeze(1))\n\n        self.log('val_loss', loss)\n        self.log('val_mae', mae)\n\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        product, search, relevance = batch\n        output = self(product, search)\n\n        # normalize relevance - min is 1, max is 3\n        relevance = (relevance - 1) / 2\n\n        loss = self.loss_fn(output, relevance.unsqueeze(1))\n        mae = self.mae(output, relevance.unsqueeze(1))\n  \n        self.log('test_loss', loss)\n        self.log('test_mae', mae)\n\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Model","metadata":{}},{"cell_type":"code","source":"model_bert = SiameseLinear(dataset.model.config.hidden_size,\n                           hp.hidden_size)\nmodel_bert.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = pl.loggers.WandbLogger(entity='questgen', project='dlw-ass3', log_model=True)\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min')\nearly_stopping = pl.callbacks.EarlyStopping(monitor='val_loss', patience=hp.patience, mode='min')\n\ntrainer = pl.Trainer(\n    accelerator='auto',\n    max_epochs=hp.num_epochs,\n    logger=logger,\n    callbacks=[checkpoint_callback, early_stopping],\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model_bert, train_loader, val_loader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the best model\nmodel_bert = SiameseLinear.load_from_checkpoint(checkpoint_callback.best_model_path, hidden_dim=hp.hidden_size, input_dim=bert_model.config.hidden_size)\n\ntrainer.test(model_bert, test_loader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{},"execution_count":null,"outputs":[]}]}